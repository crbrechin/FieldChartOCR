{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2492eda4",
      "metadata": {},
      "source": [
        "# A2 Image Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01775899",
      "metadata": {},
      "source": [
        "Each image that is taken with the camera phone will need to be normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7e85ce-f5f3-467c-bf5d-955abdf9e2a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f652674",
      "metadata": {},
      "source": [
        "## Page Zero Display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34aecd58",
      "metadata": {},
      "source": [
        "![Calibration Page Zero Display](calibration_page-0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5eb8fb",
      "metadata": {},
      "source": [
        "# Page One Display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b084ce06",
      "metadata": {},
      "source": [
        "[Calibration Page One Display](calibration_page-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba8bbbe",
      "metadata": {},
      "source": [
        "## Other Page Variants\n",
        "Now that the calibration cubes have been assessed, we turn our attention to another form of noise.\n",
        "- Dot Matrix\n",
        "- Lined\n",
        "- Blank\n",
        "- Hex"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29512ced",
      "metadata": {},
      "source": [
        "## Thoughts\n",
        "It is not lost on me that there is an infinite amount of paper types that one could imagine in order to convey ideas. Personally, the type for which I am the most nostalgic is dot matrix. An example below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ffd96f1",
      "metadata": {},
      "source": [
        "[Dot Matrix Page One](dot_matrix-page_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f8c328",
      "metadata": {},
      "source": [
        "## Describing the Calibration Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d9c050",
      "metadata": {},
      "source": [
        "*Quick Calibration Squares:*\n",
        "`6 x 6` square in every corner. Each cell in the square is `0.975mm+/- 0.500mm` wide. There are 4 distinct styles:\n",
        "- Top Left and Bottom Right QC square are the same per page (Page 0: Rear; Page 1; Front)\n",
        "    - see:\n",
        "        - [Page Zero and One Bottom Right](./p01-br.png)\n",
        "        - [Page Zero and One Top Left](./p01-tl.png)\n",
        "- The Top Right and Bottom Left of each page is the same\n",
        "    - see:\n",
        "        - [Page Zero Top Right and Bottom Left](./p0-trbl.png)\n",
        "        - [Page One Top Right and Bottom Left](./p1-trbl.png)\n",
        "\n",
        "*QC Square Envelope:*\n",
        "Each QC square has an evelope around it (as seen in any appended images of the sqaures). The envelope is `0.75in`.\n",
        "\n",
        "*Left Margin Arrows*\n",
        "Each page has directional triangles in a straight line along the Left Margin of the drawing area. There are `37` of them pointing with the tips towards the drawing area. The ratio of the triangle is such that the left edge, which is perpendicular to the column direction is `0.75in - 2mm` and the two other edges, which are congruent, are also `0.75in - 2mm`. The triangles are centered within each cell within each column and row. \n",
        "\n",
        "[Left Margin](./p01-ml.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915aa8cb",
      "metadata": {},
      "source": [
        "# Matrix Representations of QC Squares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2529b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 0: black\n",
        "# 1: white\n",
        "\n",
        "n = [ # Empty Matrix\n",
        "    [0, 0, 0, 0, 0, 0], # Row 0\n",
        "    [0, 0, 0, 0, 0, 0], # Row 1\n",
        "    [0, 0, 0, 0, 0, 0], # Row 2\n",
        "    [0, 0, 0, 0, 0, 0], # Row 3\n",
        "    [0, 0, 0, 0, 0, 0], # Row 4\n",
        "    [0, 0, 0, 0, 0, 0]  # Row 5\n",
        "]\n",
        "\n",
        "\n",
        "# Page 0 and 1, Top Left\n",
        "p01_tl = [\n",
        "    [1, 1, 1, 0, 1, 0], # Row 0\n",
        "    [0, 0, 0, 1, 0, 1], # Row 1\n",
        "    [0, 1, 0, 1, 0, 0], # Row 2\n",
        "    [1, 0, 1, 1, 1, 1], # Row 3\n",
        "    [0, 1, 1, 1, 1, 1], # Row 4\n",
        "    [1, 1, 1, 1, 1, 1] # Row 5\n",
        "]\n",
        "\n",
        "# Page 0 and 1, Bottom Right\n",
        "p01_br = [\n",
        "    [1, 1, 0, 1, 0, 0], # Row 0\n",
        "    [1, 1, 0, 1, 1, 1], # Row 1\n",
        "    [0, 1, 0, 1, 1, 1], # Row 2\n",
        "    [1, 0, 0, 1, 0, 1], # Row 3\n",
        "    [1, 1, 1, 1, 1, 1], # Row 4\n",
        "    [1, 0, 1, 1, 1, 1]  # Row 5\n",
        "]\n",
        "\n",
        "# Page 0, Top Right and Bottom Left\n",
        "p0_trbl = [\n",
        "    [1, 1, 0, 0, 1, 1], # Row 0\n",
        "    [1, 1, 1, 1, 1, 0], # Row 1\n",
        "    [0, 0, 1, 0, 0, 0], # Row 2\n",
        "    [1, 0, 0, 1, 1, 1], # Row 3\n",
        "    [1, 1, 1, 0, 1, 1], # Row 4\n",
        "    [1, 0, 1, 1, 1, 0]  # Row 5\n",
        "]\n",
        "\n",
        "# Page 1, Top Right and Bottom Left\n",
        "\n",
        "p1_trbl = [\n",
        "    [0, 0, 0, 1, 0, 1], # Row 0\n",
        "    [0, 1, 0, 0, 0, 0], # Row 1\n",
        "    [1, 0, 0, 0, 0, 1], # Row 2\n",
        "    [1, 1, 0, 1, 0, 1], # Row 3\n",
        "    [0, 1, 1, 1, 0, 0], # Row 4\n",
        "    [0, 1, 1, 0, 0, 0] # Row 5\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "505cc16e",
      "metadata": {},
      "source": [
        "### Visual Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead487ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show graph of what the QC squares look like\n",
        "\n",
        "qc_patterns = {\n",
        "    'p01_tl': np.array(p01_tl),\n",
        "    'p01_br': np.array(p01_br),\n",
        "    'p0_trbl': np.array(p0_trbl),\n",
        "    'p1_trbl': np.array(p1_trbl)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
        "for ax, (name, pattern) in zip(axes.flatten(), qc_patterns.items()):\n",
        "    ax.imshow(pattern, cmap='gray', vmin=0, vmax=1, interpolation='nearest')\n",
        "    ax.set_title(name.replace('_', ' ').upper())\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid(False)\n",
        "\n",
        "plt.suptitle('QC Square Patterns (6x6)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78070102",
      "metadata": {},
      "source": [
        "## Thought\n",
        "\n",
        "I do not approve of the imperial system, but then I didn't make the paper. In future work, I would prefer a metric version of the medium. This is something that I think would take no longer than 30 minutes to design."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ae6d0a",
      "metadata": {},
      "source": [
        "## Normalization Script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da70971",
      "metadata": {},
      "source": [
        "## Test Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e5bd7c",
      "metadata": {},
      "source": [
        "**Degenerate points**\n",
        ": points that do not form a valid geometric shape; they are collinear, overlapping, or not distinct enough to define a proper quadrilateral for transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c11aaf2",
      "metadata": {},
      "source": [
        "[011 Single](../hand_drawn_notes/bc_011_single-002.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fbd16ad",
      "metadata": {},
      "source": [
        "### Identifying Page Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc95c0c",
      "metadata": {},
      "source": [
        "**Red:** QC squares\n",
        "\n",
        "**Blue:** Triangles\n",
        "\n",
        "**Green:** Chart Area"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08555b94",
      "metadata": {},
      "source": [
        "![Page Features](../assets/generated/output_files/page_features.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3102dfae",
      "metadata": {},
      "source": [
        "### Desired Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ec976f",
      "metadata": {},
      "source": [
        "![Desired Features](../assets/generated/output_files/desired_format.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8c4e757",
      "metadata": {},
      "source": [
        "### Page Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d59801",
      "metadata": {},
      "source": [
        "![Page Dimensions](../assets/generated/output_files/page_dimensions.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66df7fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Test Image\n",
        "import PIL\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995b55e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_qc_square(image, corner='auto', search_region_size=0.2, min_square_area=100):\n",
        "    \"\"\"\n",
        "    Detect QC square in the image.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    image : numpy.ndarray\n",
        "        RGB image (H, W, 3) or BGR if from cv2.imread\n",
        "    corner : str, optional\n",
        "        Which corner to search: 'tl', 'tr', 'bl', 'br', or 'auto' (search all)\n",
        "        Default: 'auto'\n",
        "    search_region_size : float\n",
        "        Fraction of image dimensions to search in corner (0.0-1.0)\n",
        "        Default: 0.2 (top/bottom/left/right 20%)\n",
        "    min_square_area : int\n",
        "        Minimum area for detected square (in pixels)\n",
        "        Default: 100\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict or list of dicts\n",
        "        If corner='auto': list of dicts, one per detected QC square\n",
        "        Otherwise: single dict with keys:\n",
        "            - 'bbox': (x, y, width, height) bounding box\n",
        "            - 'corner': detected corner position ('tl', 'tr', 'bl', 'br')\n",
        "            - 'pattern': extracted 6x6 pattern (numpy array)\n",
        "            - 'pattern_match': matched pattern name (if successful)\n",
        "            - 'confidence': match confidence (0-1)\n",
        "    \"\"\"\n",
        "    # Convert BGR to RGB if needed (cv2 loads as BGR)\n",
        "    if len(image.shape) == 3:\n",
        "        # Check if it's likely BGR by comparing first/last channels\n",
        "        # Or just convert if from cv2.imread\n",
        "        if image.dtype == np.uint8:\n",
        "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            rgb_image = image.copy()\n",
        "    else:\n",
        "        raise ValueError(\"Image must be RGB/BGR (3 channels)\")\n",
        "    \n",
        "    h, w = rgb_image.shape[:2]\n",
        "    \n",
        "    # Define search regions for each corner\n",
        "    search_regions = {\n",
        "        'tl': (0, 0, int(w * search_region_size), int(h * search_region_size)),\n",
        "        'tr': (int(w * (1 - search_region_size)), 0, w, int(h * search_region_size)),\n",
        "        'bl': (0, int(h * (1 - search_region_size)), int(w * search_region_size), h),\n",
        "        'br': (int(w * (1 - search_region_size)), int(h * (1 - search_region_size)), w, h)\n",
        "    }\n",
        "    \n",
        "    # Convert to grayscale for detection\n",
        "    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    def detect_in_region(region_bbox, corner_name):\n",
        "        \"\"\"Detect QC square in a specific region.\"\"\"\n",
        "        rx, ry, rw, rh = region_bbox\n",
        "        region_gray = gray[ry:rh, rx:rw]\n",
        "        \n",
        "        if region_gray.size == 0:\n",
        "            return None\n",
        "        \n",
        "        # Enhance contrast for better detection\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        region_enhanced = clahe.apply(region_gray)\n",
        "        \n",
        "        # Adaptive threshold to find edges/boundaries\n",
        "        binary = cv2.adaptiveThreshold(region_enhanced, 255, \n",
        "                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                       cv2.THRESH_BINARY_INV, 11, 2)\n",
        "        \n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, \n",
        "                                       cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        # Filter for square-like contours\n",
        "        square_candidates = []\n",
        "        region_area = region_gray.shape[0] * region_gray.shape[1]\n",
        "        min_area_pixels = max(min_square_area, region_area * 0.01)  # At least 1% of region\n",
        "        \n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < min_area_pixels:\n",
        "                continue\n",
        "            \n",
        "            # Approximate polygon\n",
        "            peri = cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
        "            \n",
        "            # Check if roughly square (4 corners)\n",
        "            if len(approx) >= 4:\n",
        "                # Get bounding rect\n",
        "                x_rect, y_rect, w_rect, h_rect = cv2.boundingRect(contour)\n",
        "                \n",
        "                # Check aspect ratio (should be roughly square)\n",
        "                aspect_ratio = float(w_rect) / h_rect if h_rect > 0 else 0\n",
        "                if 0.7 < aspect_ratio < 1.3:  # Allow some tolerance\n",
        "                    # Check solidity (filled vs outline)\n",
        "                    solidity = area / (w_rect * h_rect) if (w_rect * h_rect) > 0 else 0\n",
        "                    \n",
        "                    square_candidates.append({\n",
        "                        'contour': contour,\n",
        "                        'area': area,\n",
        "                        'bbox_local': (x_rect, y_rect, w_rect, h_rect),\n",
        "                        'solidity': solidity,\n",
        "                        'aspect_ratio': aspect_ratio\n",
        "                    })\n",
        "        \n",
        "        if not square_candidates:\n",
        "            return None\n",
        "        \n",
        "        # Sort by area (largest first) and prefer more square-like shapes\n",
        "        square_candidates.sort(key=lambda x: x['area'] * x['solidity'], reverse=True)\n",
        "        best_candidate = square_candidates[0]\n",
        "        \n",
        "        # Convert local coordinates to global image coordinates\n",
        "        x_local, y_local, w_local, h_local = best_candidate['bbox_local']\n",
        "        bbox_global = (rx + x_local, ry + y_local, w_local, h_local)\n",
        "        \n",
        "        # Extract pattern from this region\n",
        "        try:\n",
        "            pattern = extract_pattern_from_rgb(rgb_image, bbox_global, envelope_margin=0.1)\n",
        "            \n",
        "            # Match pattern against known patterns\n",
        "            pattern_match, confidence = match_pattern(pattern, {\n",
        "                'p01_tl': np.array(p01_tl),\n",
        "                'p01_br': np.array(p01_br),\n",
        "                'p0_trbl': np.array(p0_trbl),\n",
        "                'p1_trbl': np.array(p1_trbl)\n",
        "            })\n",
        "            \n",
        "            return {\n",
        "                'bbox': bbox_global,\n",
        "                'corner': corner_name,\n",
        "                'pattern': pattern,\n",
        "                'pattern_match': pattern_match,\n",
        "                'confidence': confidence,\n",
        "                'area': best_candidate['area'],\n",
        "                'solidity': best_candidate['solidity']\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting pattern for {corner_name}: {e}\")\n",
        "            return {\n",
        "                'bbox': bbox_global,\n",
        "                'corner': corner_name,\n",
        "                'pattern': None,\n",
        "                'pattern_match': None,\n",
        "                'confidence': 0.0,\n",
        "                'error': str(e)\n",
        "            }\n",
        "    \n",
        "    # Search in specified corner(s)\n",
        "    if corner == 'auto':\n",
        "        results = []\n",
        "        for corner_name, region_bbox in search_regions.items():\n",
        "            result = detect_in_region(region_bbox, corner_name)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "        return results\n",
        "    else:\n",
        "        if corner not in search_regions:\n",
        "            raise ValueError(f\"Corner must be one of: {list(search_regions.keys())} or 'auto'\")\n",
        "        return detect_in_region(search_regions[corner], corner)\n",
        "\n",
        "def match_pattern(extracted_pattern, known_patterns):\n",
        "    \"\"\"\n",
        "    Match extracted 6x6 pattern against known patterns.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    extracted_pattern : numpy.ndarray\n",
        "        6x6 binary pattern\n",
        "    known_patterns : dict\n",
        "        Dictionary of pattern_name -> pattern_array\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (best_match_name, confidence_score)\n",
        "    \"\"\"\n",
        "    if extracted_pattern is None:\n",
        "        return None, 0.0\n",
        "    \n",
        "    best_match = None\n",
        "    best_score = 0.0\n",
        "    \n",
        "    for name, ref_pattern in known_patterns.items():\n",
        "        # Calculate similarity (simple matching)\n",
        "        matches = np.sum(extracted_pattern == ref_pattern)\n",
        "        similarity = matches / 36.0  # 36 cells total (6x6)\n",
        "        \n",
        "        if similarity > best_score:\n",
        "            best_score = similarity\n",
        "            best_match = name\n",
        "    \n",
        "    return best_match, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbdc8fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_pattern_from_rgb(rgb_image, bbox, envelope_margin=0.1):\n",
        "    \"\"\"\n",
        "    Extract 6x6 binary pattern from RGB image.\n",
        "    \n",
        "    envelope_margin: percentage of bbox to use as margin for envelope\n",
        "    \"\"\"\n",
        "    x, y, w, h = bbox\n",
        "    \n",
        "    # Crop region\n",
        "    qc_region_rgb = rgb_image[y:y+h, x:x+w]\n",
        "    \n",
        "    # Account for the 0.75in envelope - extract inner square\n",
        "    margin = int(min(w, h) * envelope_margin)\n",
        "    inner_region_rgb = qc_region_rgb[margin:h-margin, margin:w-margin]\n",
        "    \n",
        "    # Convert to grayscale\n",
        "    inner_gray = cv2.cvtColor(inner_region_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    # Get dimensions\n",
        "    grid_h, grid_w = inner_gray.shape\n",
        "    \n",
        "    # Divide into 6x6 cells\n",
        "    cell_h = grid_h // 6\n",
        "    cell_w = grid_w // 6\n",
        "    \n",
        "    # Extract binary pattern\n",
        "    pattern_6x6 = np.zeros((6, 6), dtype=int)\n",
        "    \n",
        "    for i in range(6):\n",
        "        for j in range(6):\n",
        "            # Sample cell center region (avoid edges between cells)\n",
        "            y_start = i * cell_h + cell_h // 4\n",
        "            y_end = (i + 1) * cell_h - cell_h // 4\n",
        "            x_start = j * cell_w + cell_w // 4\n",
        "            x_end = (j + 1) * cell_w - cell_w // 4\n",
        "            \n",
        "            if y_end > y_start and x_end > x_start:\n",
        "                cell_region = inner_gray[y_start:y_end, x_start:x_end]\n",
        "                \n",
        "                # Threshold: mean value determines if cell is black or white\n",
        "                # Black cells (filled) have low pixel values\n",
        "                # White cells (empty) have high pixel values\n",
        "                mean_value = np.mean(cell_region)\n",
        "                \n",
        "                # Adaptive threshold based on local image statistics\n",
        "                # If mean is below 128 (or use Otsu's method), it's black (filled)\n",
        "                if mean_value < 128:\n",
        "                    pattern_6x6[i, j] = 0  # black/filled\n",
        "                else:\n",
        "                    pattern_6x6[i, j] = 1  # white/empty\n",
        "    \n",
        "    return pattern_6x6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0cf8d2",
      "metadata": {},
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510ecda3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load image\n",
        "image_path = '../hand_drawn_notes/bc_011_single-000.jpg'\n",
        "image = cv2.imread(image_path)  # Returns BGR\n",
        "\n",
        "# Detect all QC squares automatically\n",
        "results = detect_qc_square(image, corner='auto', min_square_area=25)\n",
        "\n",
        "# Process results\n",
        "for result in results:\n",
        "    print(f\"Found QC square in {result['corner']} corner\")\n",
        "    print(f\"  Bounding box: {result['bbox']}\")\n",
        "    if result['pattern_match']:\n",
        "        print(f\"  Matched pattern: {result['pattern_match']}\")\n",
        "        print(f\"  Confidence: {result['confidence']:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b6604c",
      "metadata": {},
      "source": [
        "#### Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603ec246",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_qc_squares(image, results, show_labels=True, figsize=(15, 12)):\n",
        "    \"\"\"\n",
        "    Visualize detected QC squares on the original image.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    image : numpy.ndarray\n",
        "        Original RGB image\n",
        "    results : list of dicts\n",
        "        List of detection results from detect_qc_square()\n",
        "    show_labels : bool\n",
        "        Whether to show labels with corner and pattern info\n",
        "    figsize : tuple\n",
        "        Figure size for matplotlib\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object (can be saved or displayed)\n",
        "    \"\"\"\n",
        "    # Create a copy of the image to draw on\n",
        "    if len(image.shape) == 3:\n",
        "        display_image = image.copy()\n",
        "    else:\n",
        "        display_image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    # Define colors for each corner\n",
        "    corner_colors = {\n",
        "        'tl': (255, 0, 0),      # Red for top-left\n",
        "        'tr': (0, 255, 0),      # Green for top-right\n",
        "        'bl': (0, 0, 255),      # Blue for bottom-left\n",
        "        'br': (255, 165, 0),    # Orange for bottom-right\n",
        "    }\n",
        "    \n",
        "    corner_names = {\n",
        "        'tl': 'Top-Left',\n",
        "        'tr': 'Top-Right',\n",
        "        'bl': 'Bottom-Left',\n",
        "        'br': 'Bottom-Right'\n",
        "    }\n",
        "    \n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.imshow(display_image)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Draw bounding boxes for each detected QC square\n",
        "    for result in results:\n",
        "        if result is None:\n",
        "            continue\n",
        "            \n",
        "        corner = result.get('corner', 'unknown')\n",
        "        bbox = result.get('bbox', None)\n",
        "        \n",
        "        if bbox is None:\n",
        "            continue\n",
        "        \n",
        "        x, y, w, h = bbox\n",
        "        color = corner_colors.get(corner, (255, 255, 255))  # Default to white\n",
        "        \n",
        "        # Draw bounding box rectangle\n",
        "        rect = patches.Rectangle(\n",
        "            (x, y), w, h,\n",
        "            linewidth=3, \n",
        "            edgecolor=[c/255.0 for c in color], \n",
        "            facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "        # Add label if requested\n",
        "        if show_labels:\n",
        "            label_text = corner_names.get(corner, corner.upper())\n",
        "            \n",
        "            # Add pattern match info if available\n",
        "            if result.get('pattern_match'):\n",
        "                pattern_name = result['pattern_match']\n",
        "                confidence = result.get('confidence', 0)\n",
        "                label_text += f'\\n{pattern_name}\\n{confidence:.1%}'\n",
        "            \n",
        "            # Position label at top-left of bounding box\n",
        "            # Adjust if too close to image edge\n",
        "            label_x = x\n",
        "            label_y = y - 10 if y > 30 else y + h + 10\n",
        "            \n",
        "            ax.text(\n",
        "                label_x, label_y,\n",
        "                label_text,\n",
        "                fontsize=10,\n",
        "                bbox=dict(\n",
        "                    boxstyle='round,pad=0.5',\n",
        "                    facecolor=[c/255.0 for c in color],\n",
        "                    edgecolor='black',\n",
        "                    alpha=0.7\n",
        "                ),\n",
        "                color='white' if corner in ['tl', 'br'] else 'black',\n",
        "                weight='bold'\n",
        "            )\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d96942",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load image and detect QC squares\n",
        "image_path = '../hand_drawn_notes/bc_011_single-004.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Detect all QC squares\n",
        "results = detect_qc_square(rgb_image, corner='auto')\n",
        "\n",
        "# Visualize using matplotlib\n",
        "fig = visualize_qc_squares(rgb_image, results, show_labels=True)\n",
        "plt.show()\n",
        "\n",
        "# Or save the figure\n",
        "# fig.savefig('../assets/generated/output_files/qc_detections.png', dpi=150, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0452bfac",
      "metadata": {},
      "source": [
        "### Cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9364afa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_page_corners_from_qc(results, allow_diagonal_fallback=True):\n",
        "    \"\"\"\n",
        "    Extract page corner coordinates from detected QC squares.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    results : list of dicts\n",
        "        List of detection results from detect_qc_square()\n",
        "        Should contain 4 results (one for each corner)\n",
        "    allow_diagonal_fallback : bool\n",
        "        When True (default) the function will synthesize the missing corners\n",
        "        if only a TL/BR or TR/BL diagonal pair is detected.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple\n",
        "        (corner dictionary, fallback reason string or None). The dictionary has\n",
        "        keys 'tl', 'tr', 'bl', 'br'. Returns (None, None) if the required\n",
        "        corners cannot be computed.\n",
        "    \"\"\"\n",
        "    corners = {}\n",
        "    \n",
        "    for result in results:\n",
        "        if result is None:\n",
        "            continue\n",
        "        corner = result.get('corner')\n",
        "        bbox = result.get('bbox')\n",
        "        \n",
        "        if corner and bbox:\n",
        "            x, y, w, h = bbox\n",
        "            \n",
        "            # Use the outer corner of the bounding box (closest to image edge)\n",
        "            # This represents the corner of the QC square envelope\n",
        "            if corner == 'tl':\n",
        "                corners['tl'] = (x, y)\n",
        "            elif corner == 'tr':\n",
        "                corners['tr'] = (x + w, y)\n",
        "            elif corner == 'bl':\n",
        "                corners['bl'] = (x, y + h)\n",
        "            elif corner == 'br':\n",
        "                corners['br'] = (x + w, y + h)\n",
        "    \n",
        "    required_corners = ['tl', 'tr', 'bl', 'br']\n",
        "    if all(corner in corners for corner in required_corners):\n",
        "        return corners, None\n",
        "    \n",
        "    def _synthesize_from_tl_br(tl, br):\n",
        "        return {\n",
        "            'tl': tl,\n",
        "            'tr': (br[0], tl[1]),\n",
        "            'br': br,\n",
        "            'bl': (tl[0], br[1])\n",
        "        }\n",
        "    \n",
        "    def _synthesize_from_tr_bl(tr, bl):\n",
        "        return {\n",
        "            'tl': (bl[0], tr[1]),\n",
        "            'tr': tr,\n",
        "            'br': (tr[0], bl[1]),\n",
        "            'bl': bl\n",
        "        }\n",
        "    \n",
        "    if allow_diagonal_fallback:\n",
        "        if 'tl' in corners and 'br' in corners:\n",
        "            synthesized = _synthesize_from_tl_br(corners['tl'], corners['br'])\n",
        "            print(\"Partial corners detected: using TL/BR diagonal to estimate the missing corners.\")\n",
        "            return synthesized, 'diagonal_tl_br'\n",
        "        if 'tr' in corners and 'bl' in corners:\n",
        "            synthesized = _synthesize_from_tr_bl(corners['tr'], corners['bl'])\n",
        "            print(\"Partial corners detected: using TR/BL diagonal to estimate the missing corners.\")\n",
        "            return synthesized, 'diagonal_tr_bl'\n",
        "    \n",
        "    missing = [c for c in required_corners if c not in corners]\n",
        "    print(f\"Warning: Missing corners: {missing}\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def crop_image_using_qc_corners(image, results, output_size=None, margin=0, allow_diagonal_fallback=True):\n",
        "    \"\"\"\n",
        "    Crop and rectify the image using detected QC square corners.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    image : numpy.ndarray\n",
        "        Original RGB image\n",
        "    results : list of dicts\n",
        "        List of detection results from detect_qc_square()\n",
        "    output_size : tuple, optional\n",
        "        Desired output size (width, height). If None, calculates from corners.\n",
        "    margin : int or float\n",
        "        Margin to add around the page (in pixels or as fraction of page size)\n",
        "        Default: 0\n",
        "    allow_diagonal_fallback : bool\n",
        "        When True (default) synthesizes the missing corners when a TL/BR or\n",
        "        TR/BL diagonal pair is available so the page can still be rectified.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    numpy.ndarray\n",
        "        Cropped and rectified image\n",
        "    dict\n",
        "        Metadata including transformation matrix and corner coordinates\n",
        "    \"\"\"\n",
        "    # Get corner coordinates\n",
        "    corners, fallback_reason = get_page_corners_from_qc(results, allow_diagonal_fallback=allow_diagonal_fallback)\n",
        "    if corners is None:\n",
        "        raise ValueError(\"Could not extract all 4 corner points from QC squares\")\n",
        "    \n",
        "    # Source points\n",
        "    src_points = np.array([\n",
        "        corners['tl'],  # Top-left\n",
        "        corners['tr'],  # Top-right\n",
        "        corners['br'],  # Bottom-right\n",
        "        corners['bl']   # Bottom-left\n",
        "    ], dtype=np.float32)\n",
        "    \n",
        "    # Calculate destination points\n",
        "    if output_size is None:\n",
        "        # Calculate output size based on the width and height of the page\n",
        "        width_top = np.linalg.norm(src_points[1] - src_points[0])\n",
        "        width_bottom = np.linalg.norm(src_points[2] - src_points[3])\n",
        "        height_left = np.linalg.norm(src_points[3] - src_points[0])\n",
        "        height_right = np.linalg.norm(src_points[2] - src_points[1])\n",
        "        \n",
        "        # Use average dimensions\n",
        "        output_width = int(max(width_top, width_bottom))\n",
        "        output_height = int(max(height_left, height_right))\n",
        "    else:\n",
        "        output_width, output_height = output_size\n",
        "    \n",
        "    # Apply margin\n",
        "    if isinstance(margin, float):\n",
        "        margin_x = int(output_width * margin)\n",
        "        margin_y = int(output_height * margin)\n",
        "    else:\n",
        "        margin_x = margin_y = margin\n",
        "    \n",
        "    output_width += 2 * margin_x\n",
        "    output_height += 2 * margin_y\n",
        "    \n",
        "    # Destination points\n",
        "    dst_points = np.array([\n",
        "        [margin_x, margin_y],                          # Top-left\n",
        "        [output_width - margin_x, margin_y],           # Top-right\n",
        "        [output_width - margin_x, output_height - margin_y],  # Bottom-right\n",
        "        [margin_x, output_height - margin_y]           # Bottom-left\n",
        "    ], dtype=np.float32)\n",
        "    \n",
        "    # Get perspective transformation matrix\n",
        "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "    \n",
        "    # Apply perspective transformation\n",
        "    cropped = cv2.warpPerspective(\n",
        "        image, M, \n",
        "        (output_width, output_height),\n",
        "        flags=cv2.INTER_LINEAR,\n",
        "        borderMode=cv2.BORDER_CONSTANT,\n",
        "        borderValue=(255, 255, 255)  # White background for areas outside page\n",
        "    )\n",
        "    \n",
        "    metadata = {\n",
        "        'transformation_matrix': M,\n",
        "        'source_corners': corners,\n",
        "        'output_size': (output_width, output_height),\n",
        "        'margin': (margin_x, margin_y),\n",
        "        'corner_source': fallback_reason or 'detected'\n",
        "    }\n",
        "    \n",
        "    return cropped, metadata\n",
        "\n",
        "# Alternative: Use center of QC squares instead of corners\n",
        "def get_page_corners_from_qc_centers(results):\n",
        "    \"\"\"\n",
        "    Extract page corners using the center of each QC square.\n",
        "    This is useful if you want the page boundary to be at the center of the QC squares.\n",
        "    \"\"\"\n",
        "    corners = {}\n",
        "    \n",
        "    for result in results:\n",
        "        if result is None:\n",
        "            continue\n",
        "        corner = result.get('corner')\n",
        "        bbox = result.get('bbox')\n",
        "        \n",
        "        if corner and bbox:\n",
        "            x, y, w, h = bbox\n",
        "            # Use center of bounding box\n",
        "            center_x = x + w / 2\n",
        "            center_y = y + h / 2\n",
        "            corners[corner] = (center_x, center_y)\n",
        "    \n",
        "    required_corners = ['tl', 'tr', 'bl', 'br']\n",
        "    if all(corner in corners for corner in required_corners):\n",
        "        return corners\n",
        "    else:\n",
        "        missing = [c for c in required_corners if c not in corners]\n",
        "        print(f\"Warning: Missing corners: {missing}\")\n",
        "        return None\n",
        "\n",
        "# Visualization function to show the crop region\n",
        "def visualize_crop_region(image, results, show_corners=True):\n",
        "    \"\"\"\n",
        "    Visualize the crop region defined by QC squares.\n",
        "    \"\"\"\n",
        "    corners, _ = get_page_corners_from_qc(results)\n",
        "    if corners is None:\n",
        "        print(\"Cannot visualize: missing corners\")\n",
        "        return None\n",
        "    \n",
        "    # Create a copy to draw on\n",
        "    display_image = image.copy()\n",
        "    \n",
        "    # Draw lines connecting corners\n",
        "    corner_order = ['tl', 'tr', 'br', 'bl', 'tl']  # Close the polygon\n",
        "    points = [corners[corner] for corner in corner_order]\n",
        "    points = np.array(points, dtype=np.int32)\n",
        "    \n",
        "    # Draw polygon outline\n",
        "    cv2.polylines(display_image, [points], isClosed=True, \n",
        "                  color=(0, 255, 0), thickness=3)\n",
        "    \n",
        "    # Draw corner points\n",
        "    if show_corners:\n",
        "        for corner_name, (x, y) in corners.items():\n",
        "            cv2.circle(display_image, (int(x), int(y)), 10, (255, 0, 0), -1)\n",
        "            cv2.putText(display_image, corner_name.upper(), \n",
        "                       (int(x) + 15, int(y)), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "    \n",
        "    return display_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d57e6118",
      "metadata": {},
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9908880",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_cropped_result(cropped_image, title=\"Cropped and Rectified Page\", figsize=(12, 15)):\n",
        "    \"\"\"\n",
        "    Visualize the cropped/rectified image result.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    cropped_image : numpy.ndarray\n",
        "        The cropped image result\n",
        "    title : str\n",
        "        Title for the plot\n",
        "    figsize : tuple\n",
        "        Figure size for matplotlib\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.imshow(cropped_image)\n",
        "    ax.set_title(title, fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "063f42d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and detect\n",
        "image_path = '../hand_drawn_notes/bc_011_single-004.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "results = detect_qc_square(rgb_image, corner='auto')\n",
        "\n",
        "# Crop the image\n",
        "cropped_image, metadata = crop_image_using_qc_corners(\n",
        "    rgb_image, results, margin=20\n",
        ")\n",
        "\n",
        "# Show the cropped result\n",
        "fig = visualize_cropped_result(cropped_image)\n",
        "plt.figure(figsize=(12, 15))\n",
        "plt.imshow(cropped_image)\n",
        "plt.title('Cropped Result')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "fig.savefig('../assets/generated/output_files/bc_011_single_cropped.png', dpi=150, bbox_inches='tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52182bca",
      "metadata": {},
      "source": [
        "## Rotated Photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a939a71",
      "metadata": {},
      "outputs": [],
      "source": [
        "NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f796eb5",
      "metadata": {},
      "source": [
        "### Gallery of Processed Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99089f73",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gallery of Processed Images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "# from normalize_image import detect_qc_square  # adjust import path\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "image_paths = [\n",
        "\n",
        "...\n",
        "\n",
        "]  # Selection\n",
        "ncols = 3\n",
        "nrows = math.ceil(len(image_paths) / ncols)\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 3))\n",
        "\n",
        "for ax, path in zip(axes.flat, image_paths):\n",
        "  image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "  results = detect_qc_square(image, corner='auto')\n",
        "  ax.imshow(image)\n",
        "  ax.axis('off')\n",
        "  for result in results or []:\n",
        "      x, y, w, h = result['bbox']\n",
        "      color = {'tl':'red','tr':'green','bl':'blue','br':'orange'}.get(result['corner'], 'white')\n",
        "      rect = patches.Rectangle((x, y), w, h, edgecolor=color, facecolor='none', lw=2)\n",
        "      ax.add_patch(rect)\n",
        "      ax.text(x, y - 5, f\"{result['corner']} {result.get('confidence',0):.0%}\", color='white',\n",
        "              bbox=dict(facecolor=color, alpha=0.6, pad=1), fontsize=8)\n",
        "\n",
        "for ax in axes.flat[len(image_paths):]:\n",
        "  ax.remove()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../assets/generated/output_files/qc_corner_gallery.png\", dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8a7a11-f97f-45cb-b3aa-c219fd3b08f6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
